{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to merge \"addition_df\" into \"base_df\"\n",
    "# based on \"Date\" and \"Hour\" columns\n",
    "def merge_df_into(df1, df2):\n",
    "    new_df = pd.merge(df1, df2, on=['Date', 'Hour'])\n",
    "\n",
    "    # return\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B76-Traffic.csv loaded...\n",
      "B76-Traffic.csv merged...\n",
      "Timeflags.csv loaded...\n",
      "Timeflags.csv merged...\n",
      "kiel_kronshagen_hourly_weather_2019.csv loaded...\n",
      "kiel_kronshagen_hourly_weather_2019.csv merged...\n",
      "kiel_spritpreise_2019_hourly.csv loaded...\n",
      "kiel_spritpreise_2019_hourly.csv merged...\n",
      "         Date Hour NO2-ug-per-m3  Cars-Direction-1  Cars-Direction-2  \\\n",
      "0  2019-01-02   10            73               454               340   \n",
      "1  2019-01-02   11            79               495               431   \n",
      "2  2019-01-02   12            82               540               492   \n",
      "3  2019-01-02   13            72               514               493   \n",
      "4  2019-01-02   14            83               464               485   \n",
      "\n",
      "   Cars-Total  Day-Of-Week  Monday  Tuesday  Wednesday  ...  December  \\\n",
      "0         794            3       0        0          1  ...         0   \n",
      "1         926            3       0        0          1  ...         0   \n",
      "2        1032            3       0        0          1  ...         0   \n",
      "3        1007            3       0        0          1  ...         0   \n",
      "4         949            3       0        0          1  ...         0   \n",
      "\n",
      "   SchoolHoliday  wind_meters_per_second  rain_millimeters  did_it_rain  \\\n",
      "0              1                     9.9               0.0            0   \n",
      "1              1                     9.7               0.0            0   \n",
      "2              1                     9.6               0.0            0   \n",
      "3              1                     9.3               0.0            0   \n",
      "4              1                     9.6               0.0            0   \n",
      "\n",
      "   air_temp_deg_c  relative_humidity_percent        e5       e10    diesel  \n",
      "0             4.1                       52.0  1.358255  1.331766  1.201128  \n",
      "1             4.3                       52.0  1.393599  1.366445  1.235934  \n",
      "2             4.4                       51.0  1.364844  1.340429  1.206922  \n",
      "3             4.2                       51.0  1.348851  1.323179  1.190269  \n",
      "4             4.0                       50.0  1.317175  1.293286  1.169714  \n",
      "\n",
      "[5 rows x 35 columns]\n"
     ]
    }
   ],
   "source": [
    "all  = pd.DataFrame()\n",
    "\n",
    "dataset_names = [\n",
    "    'B76-NO2.csv',\n",
    "    'B76-Traffic.csv',\n",
    "    'Timeflags.csv',\n",
    "    'kiel_kronshagen_hourly_weather_2019.csv',\n",
    "    'kiel_spritpreise_2019_hourly.csv'\n",
    "]\n",
    "\n",
    "# check if all the files exists\n",
    "for dataset_name in dataset_names:\n",
    "    if not os.path.exists(os.path.join('datasets', dataset_name)):\n",
    "        print('File {} does not exist!'.format(dataset_name))\n",
    "        sys.exit(1)\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "for i in range(len(dataset_names)):\n",
    "    dataset_name = dataset_names[i]\n",
    "    if i > 0:\n",
    "        # read dataset\n",
    "        additional_df = pd.read_csv('datasets/' + dataset_name)\n",
    "        additional_df['Hour'] = additional_df['Hour'].astype(int)\n",
    "        print(dataset_name, 'loaded...')\n",
    "        # merge into all\n",
    "        new_df = merge_df_into(new_df, additional_df)\n",
    "        print(dataset_name, 'merged...')\n",
    "    else:\n",
    "        new_df = pd.read_csv('datasets/' + dataset_name)\n",
    "\n",
    "\n",
    "# save the merged dataset\n",
    "new_df.to_csv(\"datasets/all.csv\", index=False)\n",
    "# print head\n",
    "print(new_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
